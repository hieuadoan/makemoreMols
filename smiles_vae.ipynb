{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0.post301\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# Print torch version\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35466\n",
      "20\n",
      "['C', 'N', 'O', 'C#C', 'C#N', 'N#N', 'C=C', 'C=N']\n"
     ]
    }
   ],
   "source": [
    "# Load SMILES data\n",
    "smiles = open('data/1to6.dmu.smi','r').read().splitlines()\n",
    "smiles\n",
    "print(len(smiles))\n",
    "max_len = max(len(w) for w in smiles)\n",
    "print(max_len)\n",
    "print(smiles[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: '#', 2: '(', 3: ')', 4: '1', 5: '2', 6: '3', 7: '4', 8: '5', 9: '=', 10: 'C', 11: 'N', 12: 'O', 0: '.'}\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(smiles))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the smiles\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28372, 20])\n",
      "torch.Size([3547, 20])\n",
      "torch.Size([3547, 20])\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 20\n",
    "EMB_DIM = 20\n",
    "LAT_DIM = 10\n",
    "\n",
    "# build the dataset\n",
    "def build_dataset(smiles):\n",
    "    X = []\n",
    "    for s in smiles:\n",
    "        x = []\n",
    "        for ch in s:\n",
    "            ix = stoi[ch]\n",
    "            x.append(ix)\n",
    "        while len(x) < SEQ_LEN:\n",
    "            x.append(0)\n",
    "        X.append(x)\n",
    "    X = torch.tensor(X)\n",
    "    print(X.shape)\n",
    "    return X\n",
    "n1 = int(0.8 * len(smiles))\n",
    "n2 = int(0.9 * len(smiles))\n",
    "Xtr = build_dataset(smiles[:n1])\n",
    "Xdev = build_dataset(smiles[n1:n2])\n",
    "Xte = build_dataset(smiles[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC1CC(=C)C1......... --> [10, 10, 4, 10, 10, 2, 9, 10, 3, 10, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "C#CN1OCO1........... --> [10, 1, 10, 11, 4, 12, 10, 12, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "N=CC=CN=O........... --> [11, 9, 10, 10, 9, 10, 11, 9, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "N=C=C1ON=C1......... --> [11, 9, 10, 9, 10, 4, 12, 11, 9, 10, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "O=C1NN=NO1.......... --> [12, 9, 10, 4, 11, 11, 9, 11, 12, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CCN(N)NN............ --> [10, 10, 11, 2, 11, 3, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "C1NN2ONC12.......... --> [10, 4, 11, 11, 5, 12, 11, 10, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "ONC1=C(O)N1......... --> [12, 11, 10, 4, 9, 10, 2, 12, 3, 11, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NN1C2NC12........... --> [11, 11, 4, 10, 5, 11, 10, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NC(=O)N=C=N......... --> [11, 10, 2, 9, 12, 3, 11, 9, 10, 9, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CC#CNCN............. --> [10, 10, 1, 10, 11, 10, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CCC1(N)NO1.......... --> [10, 10, 10, 4, 2, 11, 3, 11, 12, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NN=NC=C............. --> [11, 11, 9, 11, 10, 9, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CN=C1CN=N1.......... --> [10, 11, 9, 10, 4, 10, 11, 9, 11, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "C1=CC2=C=C=C12...... --> [10, 4, 9, 10, 10, 5, 9, 10, 9, 10, 9, 10, 4, 5, 0, 0, 0, 0, 0, 0]\n",
      "CC#CCC#C............ --> [10, 10, 1, 10, 10, 10, 1, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "OOC12CC1N2.......... --> [12, 12, 10, 4, 5, 10, 10, 4, 11, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NON=C=C............. --> [11, 12, 11, 9, 10, 9, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "OC12C3CC1N23........ --> [12, 10, 4, 5, 10, 6, 10, 10, 4, 11, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "C=C1C(=C)C1=C....... --> [10, 9, 10, 4, 10, 2, 9, 10, 3, 10, 4, 9, 10, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for x in Xtr[-20:]:\n",
    "    print(''.join(itos[ix.item()] for ix in x), '-->', x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Variational Autoencoder model\n",
    "class VAE_smiles(nn.Module):\n",
    "    def __init__(self, seq_len = SEQ_LEN, vocab_size=13, emb_dim = EMB_DIM, hidden_dim=100, latent_dim=LAT_DIM):\n",
    "        super().__init__()\n",
    "    \n",
    "        # ecoder    \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)  \n",
    "        self.rnn_emb2hid = nn.GRU(emb_dim, hidden_dim, batch_first=True)   \n",
    "        self.fc_hid2mean = nn.Linear(hidden_dim, latent_dim)   \n",
    "        self.fc_hid2logvar = nn.Linear(hidden_dim, latent_dim)  \n",
    "        \n",
    "        # decoder\n",
    "        self.fc_lat2hid = nn.Linear(latent_dim, hidden_dim)  \n",
    "        self.rnn_hid2emb = nn.GRU(emb_dim, hidden_dim, batch_first=True)  \n",
    "        self.fc_emb2out = nn.Linear(hidden_dim, vocab_size)   \n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = self.emb(x)   # (B,20,20)\n",
    "        _, hn_e = self.rnn_emb2hid(x)  # (1, B, 200) \n",
    "        hn_e = hn_e.squeeze(0)  # (B, 200)\n",
    "        mean = self.fc_hid2mean(hn_e)  #   (B,10)\n",
    "        logvar = self.fc_hid2logvar(hn_e)  #  (B,10)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterization(self, mean, logvar):\n",
    "        epsilon = torch.randn_like(logvar)\n",
    "        z = mean + logvar * epsilon\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):  # (B, 10)\n",
    "        hn_d = self.fc_lat2hid(z) # (B, 200)\n",
    "        hn_d = hn_d.unsqueeze(0)  # (1, B, 200)\n",
    "        h0 = torch.zeros(z.size(0), SEQ_LEN, EMB_DIM).to(device)  # (B, 20, 20)\n",
    "        z, _ = self.rnn_hid2emb(h0, hn_d) # (B, 20, 20) \n",
    "        x = self.fc_emb2out(z) # (B, 20, 13)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterization(mean, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mean, logvar   \n",
    "\n",
    "# Loss function\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.cross_entropy(x_hat, x)\n",
    "    KLD = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "    return reproduction_loss + KLD                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20, 13]) 77893\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "Xb = torch.randint(0,vocab_size,(batch_size,SEQ_LEN)).to(device)\n",
    "print(Xb.shape)\n",
    "#model = VAE_smiles_WaveNet(seq_len=SEQ_LEN)\n",
    "model = VAE_smiles(seq_len=SEQ_LEN).to(device)\n",
    "x, _, _ = model(Xb)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(x.shape, total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieu/miniconda3/envs/mlmat/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch 0 \tLoss:  5.747844696044922\n",
      "\tEpoch 10000 \tLoss:  0.8063761591911316\n",
      "\tEpoch 20000 \tLoss:  0.6139052510261536\n",
      "\tEpoch 30000 \tLoss:  0.6027733087539673\n",
      "\tEpoch 40000 \tLoss:  0.5145543813705444\n",
      "\tEpoch 50000 \tLoss:  0.48320817947387695\n",
      "Checkpoint saved at iteration 50000\n",
      "\tEpoch 60000 \tLoss:  0.41425931453704834\n",
      "\tEpoch 70000 \tLoss:  0.4497325122356415\n",
      "\tEpoch 80000 \tLoss:  0.3373427093029022\n",
      "\tEpoch 90000 \tLoss:  0.3248225152492523\n",
      "\tEpoch 100000 \tLoss:  0.2829974293708801\n",
      "Checkpoint saved at iteration 100000\n",
      "\tEpoch 110000 \tLoss:  0.2786678075790405\n",
      "\tEpoch 120000 \tLoss:  0.2688663601875305\n",
      "\tEpoch 130000 \tLoss:  0.23895548284053802\n",
      "\tEpoch 140000 \tLoss:  0.5180830955505371\n",
      "\tEpoch 150000 \tLoss:  0.2092927247285843\n",
      "Checkpoint saved at iteration 150000\n",
      "\tEpoch 160000 \tLoss:  0.20241442322731018\n",
      "\tEpoch 170000 \tLoss:  0.1529400795698166\n",
      "\tEpoch 180000 \tLoss:  0.14882642030715942\n",
      "\tEpoch 190000 \tLoss:  0.13575328886508942\n",
      "\tEpoch 200000 \tLoss:  0.13754743337631226\n",
      "Checkpoint saved at iteration 200000\n",
      "\tEpoch 210000 \tLoss:  0.12393447011709213\n",
      "\tEpoch 220000 \tLoss:  0.130397230386734\n",
      "\tEpoch 230000 \tLoss:  0.12097261846065521\n",
      "\tEpoch 240000 \tLoss:  0.09642110764980316\n",
      "\tEpoch 250000 \tLoss:  0.13594207167625427\n",
      "Checkpoint saved at iteration 250000\n",
      "\tEpoch 260000 \tLoss:  0.10951682180166245\n",
      "\tEpoch 270000 \tLoss:  0.09332829713821411\n",
      "\tEpoch 280000 \tLoss:  0.10807383805513382\n",
      "\tEpoch 290000 \tLoss:  0.1026308536529541\n",
      "\tEpoch 300000 \tLoss:  0.08724861592054367\n",
      "Checkpoint saved at iteration 300000\n"
     ]
    }
   ],
   "source": [
    "model = VAE_smiles().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "epochs = 310000\n",
    "batch_size = 64\n",
    "lossi = []\n",
    "for epoch in range(epochs):\n",
    "    # Sample batch\n",
    "    idx = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xb = Xtr[idx].to(device)\n",
    "    \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x_hat, mean, log_var = model(Xb)\n",
    "    loss = loss_function(Xb.view(-1), x_hat.view(-1, vocab_size), mean, log_var)\n",
    "    lossi.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10000 == 0:\n",
    "        print(\"\\tEpoch\", epoch, \"\\tLoss: \", loss.item())\n",
    "    \n",
    "    modelName = 'VAE_smiles'\n",
    "    if epoch % 50000 == 0 and epoch > 0:\n",
    "        checkpoint = {\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "            'iteration': epoch\n",
    "        }\n",
    "        torch.save(checkpoint, f'models/{modelName}_checkpoint_{epoch}.pt')\n",
    "        print(f'Checkpoint saved at iteration {epoch}')\n",
    "    if epoch > 150000:\n",
    "        lr = 1e-4\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.1233,  1.7622,  0.4081,  0.6715,  0.3010, -2.4946,  0.0414,  0.1042,\n",
      "         1.6998,  0.5618])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[20:16:07] SMILES Parse Error: syntax error while parsing: #CCCCCCCCCCCCCCCCCCC\n",
      "[20:16:07] SMILES Parse Error: Failed parsing SMILES '#CCCCCCCCCCCCCCCCCCC' for input: '#CCCCCCCCCCCCCCCCCCC'\n"
     ]
    },
    {
     "ename": "ArgumentError",
     "evalue": "Python argument types in\n    rdkit.Chem.rdmolfiles.MolToSmiles(NoneType)\ndid not match C++ signature:\n    MolToSmiles(RDKit::ROMol mol, bool isomericSmiles=True, bool kekuleSmiles=False, int rootedAtAtom=-1, bool canonical=True, bool allBondsExplicit=False, bool allHsExplicit=False, bool doRandom=False)\n    MolToSmiles(RDKit::ROMol mol, RDKit::SmilesWriteParams params)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(samp)\n\u001b[1;32m     20\u001b[0m gen_smiles \u001b[38;5;241m=\u001b[39m generate_smiles(samp\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m---> 21\u001b[0m \u001b[38;5;28mprint\u001b[39m(gen_smiles, \u001b[43mChem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMolToSmiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mChem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMolFromSmiles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgen_smiles\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mArgumentError\u001b[0m: Python argument types in\n    rdkit.Chem.rdmolfiles.MolToSmiles(NoneType)\ndid not match C++ signature:\n    MolToSmiles(RDKit::ROMol mol, bool isomericSmiles=True, bool kekuleSmiles=False, int rootedAtAtom=-1, bool canonical=True, bool allBondsExplicit=False, bool allHsExplicit=False, bool doRandom=False)\n    MolToSmiles(RDKit::ROMol mol, RDKit::SmilesWriteParams params)"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "model = VAE_smiles().to(device)\n",
    "checkpoint = torch.load('models/VAE_smiles_checkpoint_300000.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "latent_dim = LAT_DIM\n",
    "def generate_smiles(z):\n",
    "    z_sample = torch.tensor([z], dtype=torch.float).to(device)\n",
    "    logits = model.decode(z_sample)\n",
    "    logits = logits.view(-1, vocab_size)\n",
    "    prob = nn.functional.softmax(logits, dim=1)\n",
    "    #indices = torch.argmax(prob, dim=-1)\n",
    "    indices = torch.multinomial(prob, num_samples=1).squeeze(-1)\n",
    "    #print(indices)\n",
    "    return ''.join(itos[ix.item()] for ix in indices).replace('.','')\n",
    "    #return indices\n",
    "samp = torch.randn(latent_dim)\n",
    "#samp = torch.tensor([0,0])\n",
    "print(samp)\n",
    "gen_smiles = generate_smiles(samp.tolist())\n",
    "print(gen_smiles, Chem.MolToSmiles(Chem.MolFromSmiles(gen_smiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid SMILES: 1721/10000\n",
      "Unique SMILES: 272/1721\n"
     ]
    }
   ],
   "source": [
    "# Suppress RDKit warnings\n",
    "from rdkit import RDLogger\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "uniqueList = []\n",
    "validCount = 0\n",
    "for i in range(10000):\n",
    "    samp = torch.rand(LAT_DIM)\n",
    "    smi = generate_smiles(samp.tolist())\n",
    "    if Chem.MolFromSmiles(smi):\n",
    "        validCount+=1\n",
    "        canon_smi = Chem.MolToSmiles(Chem.MolFromSmiles(smi))\n",
    "        if canon_smi not in uniqueList:\n",
    "            uniqueList.append(canon_smi)\n",
    "\n",
    "print(f'Valid SMILES: {validCount}/10000')\n",
    "print(f'Unique SMILES: {len(uniqueList)}/{validCount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CCCCC', 'CCCCCCCCCCCCCCCCCCCC', 'CCCCCCC', 'CCCCCCCNC', 'CC', 'C1CC1', 'CCNC', 'CC=CCCCC', 'CC#CC', 'CCCCC1CCCCCCCCCC1CCC', 'CCCCCC', 'CCC', 'CCCNC', 'CCOCC', 'C1=NNNN2CC2N1', 'CC#CCCCC', 'CCOCCO', 'C#CCCCC', 'CNC', 'C#C', 'CCCOC', 'CCCCCC=CC=CCCCCCCCCC', 'C1CCCCCC1', 'C#CC', 'CC=CCC', 'CC=CCCCCC', 'CC#CCC', 'CCNCN', 'CC#CCCC', 'CCCCCCCCCCO', 'C#CCCCCCCC', 'CCCCCCC1CC1', 'C#CCCCCCC', 'CCCC', 'CC1CC1N', 'CC#N', 'C1=CCC1', 'C#CCCC', 'CCCCCCCC', 'CCC1CCCO1', 'C#CCC', 'CCNCC', 'CCC1CC1', 'CCCCCCCCNCCNNCCCCCCC', 'CCCCCCCOCCC', 'C=CC', 'C=CCC', 'C1COOONO1', 'C1=CC1', 'CCCN', 'CC#CCCCCCCCCC', 'CCCCCCCCCCC1CC12CC2C', 'CCCCCCCCCCCNC', 'CCCCOC', 'C1COC1', 'CC#CCCCCCCCCCC', 'CCCC1CC1', 'CC=CCCC', 'C=CCCCCCCCCCCCCCCNNC', 'CC=C=NNNNNNCCCCCCCCC', 'CO', 'COC', 'C', 'CCCC#N', 'C1=CCCCCC1', 'CCCCCCCNNC', 'CCCNCC', 'C#CCCCCCCCC', 'COOO', 'CCCCCC1CCCCCCC1C1CC1', 'CCCCOCC', 'CCCCCC#N', 'CCN', 'C#CC=C', 'CNO', 'CCCCNC', 'CCCCCCCC1CC12CCCC2CC', 'CCCCCCCCC', 'CCC1CCCCCCCCCCCCCCC1', 'C1C2OOC1O2', 'CCCCCCCCCCC', 'CCCCCNC', 'C=CCCCC', 'CCC1CCC1', 'CCCCCCCCCCCCCCC1CCC1', 'CCCCCCCCCCCCC1CCC1CC', 'CCC1NON1', 'CCCCCCCCCCCCCC', 'C1CN1', 'C=CCCCCC', 'CCCCCCCCCCCCCCC', 'CC#CCCCCC', 'C=CCCCCNNC', 'CCCCCNCC', 'CCCCCCCCCCCCCC1CCCC1', 'CCC1CCC12CCCCCCCCCC2', 'CCCCCC1CN1', 'CCCCCCOC', 'CCCCCCCCCC', 'C1=CCOC1', 'CON', 'CCCC1CCC1', 'CCOC', 'C#CCNC', 'C1NOO1', 'CCCCCCNC', 'CCCCNCC', 'CCCCNNCC', 'C1=CCNNNC1', 'CCCNNC', 'CCCCC#N', 'CCC=N', 'CCCCCCCCCCCCC1CC1CCC', 'C1COCCO1', 'CCCOCC', 'CC=CC', 'CCCCC1CCCNCCCCCC1CCC', 'CCCCCCCCC1CN1', 'CCCC=CCCCCCCCCCCCCCC', 'C=C', 'CCC#CCCC', 'CCCCNNCCNN1NCNNCCC1C', 'C1=NNNCC2CCCC2O1', 'CCCCCCCCCCCNCCCCCCNC', 'CCCCCC#CN', 'CCCCCCCCCCCC1CCC1CCC', 'CC#CCCCCCC', 'CNN', 'C=CCCCCCC', 'CCCCNN', 'OOOOOOOOOOOOOOOOOOOO', 'C1COCO1', 'C#N', 'C#CCCCCCCCCCCCC', 'COO', 'C#CC#CC', 'CC=CCCCCCC', 'C1=CCONC1', 'CCOO', 'C=CCC=C', 'CC#CCCCCCCC', 'CCCCCCNNC', 'CCOCN', 'C1CCCCCCC1', 'CCCCC=CN', 'C1CNOC1', 'C=CCCNCC', 'CCCOCN', '', 'C1COCN1', 'CNCO', 'C1CCCCCCCCCCCCCCCCC1', 'CCCCCCCN', 'C1=NCCNCNNNN1', 'CCCC=CCNNN', 'CCC1CCCCC1', 'C1CCCC1', 'CCCCCNOC', 'OC1CC1', 'CCCNCN', 'CCCCCCCCCCCCCCCCCCNN', 'CCC=CCC', 'CN', 'CCCCCCCCCCCCCCCCC', 'CC1CC1', 'CCCCCC1CC1C1CCCCCC1C', 'CCCCCCCCCC1CCCCCCC1C', 'C=CC=CC', 'C=CCC=CC', 'CCCCCCCCCCCCCCCCCCCN', 'C#CCCCCC', 'CCCCCC1CCCCCCCCCC1CC', 'C#CCCCCCCCCCCCCCCCCC', 'CCCCCNOO', 'C=CC=C', 'CCCCCCCCCNC', 'CCCC1CCCCCCCC1CC', 'CCC1CCCC1', 'C=CCCC', 'CCCCCCCCCC1CCN1', 'C=N', 'CCON', 'C1=CN=C1', 'CCCCCCCCCCCCC1CCCCC1', 'CCC#N', 'CCN1CC1C', 'CCNNN', 'CCCOO', 'CC1CCO1', 'CCCCCCCCCCN', 'CCCCCCCCCC#CN', 'C#COCC', 'CC=CCC=CCCCCCCCCCCCC', 'CC1CC2OCC12', 'CCCCCCC#CO', 'C1=CCCC1', 'C#CCO', 'C#CCCCCCCCCCC', 'CC1CCC1', 'CCCCC1CC1', 'CCCCCCOCC', 'C#CCC=CC', 'C1NNNNNNN1', 'CCCCCCCCCCCC1CCCCCC1', 'C1CCCCC1', 'CCCNN', 'CCCO', 'CCCCCCNN', 'CCCCCCCCCCC1CCCCCC1C', 'C1CC2CNONC2C1', 'CCCCC#CN', 'C#CCCNOC', 'CCCCCCCC1CC1', 'CCCCCCO', 'C1CC2NOC2C1', 'NC1CC1', 'CCC=CCCCC', 'C=CCNCC', 'CCCCCCCCNN', 'C1COO1', 'C#COCCC', 'CCCNCCNON', 'CCCCCCCCCCCCCCON', 'C=CCCCCCCCC', 'CCCCCCCCCCCCCCCCNNCC', 'CCCCCCCCC1CO1', 'CCCC1CC12CCCCCCCCC2C', 'CCC1CO1', 'CCCCN', 'C=CCCCCCCCCCCC', 'CCC1CCCCCCCCOC1', 'CCCCCCCCCCCCCCCCCCCO', 'CCC1CN1', 'C1CCNNCC1', 'CC=NCNOC', 'C1COOO1', 'CCCCCC1CC1', 'CCCC1CNC1', 'CCC1CCNC1', 'C=C1CO1', 'CCCCOO', 'CCCCCCCCCC1CC1CCCCCC', 'C#COCO', 'C1CCNCC1', 'C=C=CCCCCC', 'CCCCC1CN1', 'CCCCCCCCCCCCCCCNN', 'C=CCCCNCC', 'CCC1CCO1', 'CCCCCNNC', 'CCCCCCCCC1CC1CCCCCCC', 'CCC=CCNOC', 'CCCCCCCC1CCCCCCCC1=O', 'CCCCNOC', 'CCCCCCCNCNNN1CCC1CCC', 'CCCCCCCCC1CCCC1CCCCC', 'CCCCCCCCC1CCCC12CC2C', 'CC1C=CCC1', 'C#CCCCCCCCCCCCCC', 'CC#CC#N', 'CCC1CCCCCCCC12CC2CC', 'C=CCC=NN', 'C1CC2ONC12', 'CCCCCCNOO', 'C=CCCC=CN', 'CC1CC1O', 'C1CCCCCCCC1', 'C1=NCC1', 'CCCCC1CCC1CC1CCCCCC1', 'C1=CCN=C1', 'C1CO1', 'CCCCCCCCCCNNC']\n"
     ]
    }
   ],
   "source": [
    "print(uniqueList)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
