{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0.post301\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "# Print torch version\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cuda\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35466\n",
      "20\n",
      "['C', 'N', 'O', 'C#C', 'C#N', 'N#N', 'C=C', 'C=N']\n"
     ]
    }
   ],
   "source": [
    "# Load SMILES data\n",
    "smiles = open('data/1to6.dmu.smi','r').read().splitlines()\n",
    "smiles\n",
    "print(len(smiles))\n",
    "max_len = max(len(w) for w in smiles)\n",
    "print(max_len)\n",
    "print(smiles[:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: '#', 2: '(', 3: ')', 4: '1', 5: '2', 6: '3', 7: '4', 8: '5', 9: '=', 10: 'C', 11: 'N', 12: 'O', 0: '.'}\n",
      "13\n"
     ]
    }
   ],
   "source": [
    "# build the vocabulary of characters and mappings to/from integers\n",
    "chars = sorted(list(set(''.join(smiles))))\n",
    "stoi = {s:i+1 for i,s in enumerate(chars)}\n",
    "stoi['.'] = 0\n",
    "itos = {i:s for s,i in stoi.items()}\n",
    "vocab_size = len(itos)\n",
    "print(itos)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the smiles\n",
    "import random\n",
    "random.seed(42)\n",
    "random.shuffle(smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([28372, 20])\n",
      "torch.Size([3547, 20])\n",
      "torch.Size([3547, 20])\n"
     ]
    }
   ],
   "source": [
    "SEQ_LEN = 20\n",
    "EMB_DIM = 20\n",
    "LAT_DIM = 10\n",
    "\n",
    "# build the dataset\n",
    "def build_dataset(smiles):\n",
    "    X = []\n",
    "    for s in smiles:\n",
    "        x = []\n",
    "        for ch in s:\n",
    "            ix = stoi[ch]\n",
    "            x.append(ix)\n",
    "        while len(x) < SEQ_LEN:\n",
    "            x.append(0)\n",
    "        X.append(x)\n",
    "    X = torch.tensor(X)\n",
    "    print(X.shape)\n",
    "    return X\n",
    "n1 = int(0.8 * len(smiles))\n",
    "n2 = int(0.9 * len(smiles))\n",
    "Xtr = build_dataset(smiles[:n1])\n",
    "Xdev = build_dataset(smiles[n1:n2])\n",
    "Xte = build_dataset(smiles[n2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CC1CC(=C)C1......... --> [10, 10, 4, 10, 10, 2, 9, 10, 3, 10, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "C#CN1OCO1........... --> [10, 1, 10, 11, 4, 12, 10, 12, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "N=CC=CN=O........... --> [11, 9, 10, 10, 9, 10, 11, 9, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "N=C=C1ON=C1......... --> [11, 9, 10, 9, 10, 4, 12, 11, 9, 10, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "O=C1NN=NO1.......... --> [12, 9, 10, 4, 11, 11, 9, 11, 12, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CCN(N)NN............ --> [10, 10, 11, 2, 11, 3, 11, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "C1NN2ONC12.......... --> [10, 4, 11, 11, 5, 12, 11, 10, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "ONC1=C(O)N1......... --> [12, 11, 10, 4, 9, 10, 2, 12, 3, 11, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NN1C2NC12........... --> [11, 11, 4, 10, 5, 11, 10, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NC(=O)N=C=N......... --> [11, 10, 2, 9, 12, 3, 11, 9, 10, 9, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CC#CNCN............. --> [10, 10, 1, 10, 11, 10, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CCC1(N)NO1.......... --> [10, 10, 10, 4, 2, 11, 3, 11, 12, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NN=NC=C............. --> [11, 11, 9, 11, 10, 9, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "CN=C1CN=N1.......... --> [10, 11, 9, 10, 4, 10, 11, 9, 11, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "C1=CC2=C=C=C12...... --> [10, 4, 9, 10, 10, 5, 9, 10, 9, 10, 9, 10, 4, 5, 0, 0, 0, 0, 0, 0]\n",
      "CC#CCC#C............ --> [10, 10, 1, 10, 10, 10, 1, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "OOC12CC1N2.......... --> [12, 12, 10, 4, 5, 10, 10, 4, 11, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "NON=C=C............. --> [11, 12, 11, 9, 10, 9, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "OC12C3CC1N23........ --> [12, 10, 4, 5, 10, 6, 10, 10, 4, 11, 5, 6, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "C=C1C(=C)C1=C....... --> [10, 9, 10, 4, 10, 2, 9, 10, 3, 10, 4, 9, 10, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "for x in Xtr[-20:]:\n",
    "    print(''.join(itos[ix.item()] for ix in x), '-->', x.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Variational Autoencoder model\n",
    "class VAE_smiles(nn.Module):\n",
    "    def __init__(self, seq_len = SEQ_LEN, vocab_size=13, emb_dim = EMB_DIM, hidden_dim=100, latent_dim=LAT_DIM):\n",
    "        super().__init__()\n",
    "    \n",
    "        # ecoder    \n",
    "        self.emb = nn.Embedding(vocab_size, emb_dim, padding_idx=0)  \n",
    "        self.rnn_emb2hid = nn.GRU(emb_dim, hidden_dim, batch_first=True)   \n",
    "        self.fc_hid2mean = nn.Linear(hidden_dim, latent_dim)   \n",
    "        self.fc_hid2logvar = nn.Linear(hidden_dim, latent_dim)  \n",
    "        \n",
    "        # decoder\n",
    "        self.fc_lat2hid = nn.Linear(latent_dim, hidden_dim)  \n",
    "        self.rnn_hid2emb = nn.GRU(emb_dim, hidden_dim, batch_first=True)  \n",
    "        self.fc_emb2out = nn.Linear(hidden_dim, vocab_size)   \n",
    "    \n",
    "    def encode(self, x):\n",
    "        x = self.emb(x)   # (B,20,20)\n",
    "        _, hn_e = self.rnn_emb2hid(x)  # (1, B, 200) \n",
    "        hn_e = hn_e.squeeze(0)  # (B, 200)\n",
    "        mean = self.fc_hid2mean(hn_e)  #   (B,10)\n",
    "        logvar = self.fc_hid2logvar(hn_e)  #  (B,10)\n",
    "        return mean, logvar\n",
    "    \n",
    "    def reparameterization(self, mean, logvar):\n",
    "        epsilon = torch.randn_like(logvar)\n",
    "        z = mean + logvar * epsilon\n",
    "        return z\n",
    "    \n",
    "    def decode(self, z):  # (B, 10)\n",
    "        hn_d = self.fc_lat2hid(z) # (B, 200)\n",
    "        hn_d = hn_d.unsqueeze(0)  # (1, B, 200)\n",
    "        h0 = torch.zeros(z.size(0), SEQ_LEN, EMB_DIM).to(device)  # (B, 20, 20)\n",
    "        z, _ = self.rnn_hid2emb(h0, hn_d) # (B, 20, 20) \n",
    "        x = self.fc_emb2out(z) # (B, 20, 13)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mean, logvar = self.encode(x)\n",
    "        z = self.reparameterization(mean, logvar)\n",
    "        x_hat = self.decode(z)\n",
    "        return x_hat, mean, logvar   \n",
    "\n",
    "# Loss function\n",
    "def loss_function(x, x_hat, mean, log_var):\n",
    "    reproduction_loss = nn.functional.cross_entropy(x_hat, x)\n",
    "    KLD = - 0.5 * torch.sum(1+ log_var - mean.pow(2) - log_var.exp())\n",
    "    return reproduction_loss + KLD                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 20])\n",
      "torch.Size([64, 20, 13]) 77893\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "Xb = torch.randint(0,vocab_size,(batch_size,SEQ_LEN)).to(device)\n",
    "print(Xb.shape)\n",
    "#model = VAE_smiles_WaveNet(seq_len=SEQ_LEN)\n",
    "model = VAE_smiles(seq_len=SEQ_LEN).to(device)\n",
    "x, _, _ = model(Xb)\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(x.shape, total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hieu/miniconda3/envs/mlmat/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch 0 \tLoss:  5.747844696044922\n",
      "\tEpoch 10000 \tLoss:  0.8063761591911316\n",
      "\tEpoch 20000 \tLoss:  0.6139052510261536\n",
      "\tEpoch 30000 \tLoss:  0.6027733087539673\n",
      "\tEpoch 40000 \tLoss:  0.5145543813705444\n",
      "\tEpoch 50000 \tLoss:  0.48320817947387695\n",
      "Checkpoint saved at iteration 50000\n",
      "\tEpoch 60000 \tLoss:  0.41425931453704834\n",
      "\tEpoch 70000 \tLoss:  0.4497325122356415\n",
      "\tEpoch 80000 \tLoss:  0.3373427093029022\n",
      "\tEpoch 90000 \tLoss:  0.3248225152492523\n",
      "\tEpoch 100000 \tLoss:  0.2829974293708801\n",
      "Checkpoint saved at iteration 100000\n",
      "\tEpoch 110000 \tLoss:  0.2786678075790405\n",
      "\tEpoch 120000 \tLoss:  0.2688663601875305\n",
      "\tEpoch 130000 \tLoss:  0.23895548284053802\n",
      "\tEpoch 140000 \tLoss:  0.5180830955505371\n",
      "\tEpoch 150000 \tLoss:  0.2092927247285843\n",
      "Checkpoint saved at iteration 150000\n",
      "\tEpoch 160000 \tLoss:  0.20241442322731018\n",
      "\tEpoch 170000 \tLoss:  0.1529400795698166\n",
      "\tEpoch 180000 \tLoss:  0.14882642030715942\n",
      "\tEpoch 190000 \tLoss:  0.13575328886508942\n",
      "\tEpoch 200000 \tLoss:  0.13754743337631226\n",
      "Checkpoint saved at iteration 200000\n",
      "\tEpoch 210000 \tLoss:  0.12393447011709213\n",
      "\tEpoch 220000 \tLoss:  0.130397230386734\n",
      "\tEpoch 230000 \tLoss:  0.12097261846065521\n",
      "\tEpoch 240000 \tLoss:  0.09642110764980316\n",
      "\tEpoch 250000 \tLoss:  0.13594207167625427\n",
      "Checkpoint saved at iteration 250000\n",
      "\tEpoch 260000 \tLoss:  0.10951682180166245\n",
      "\tEpoch 270000 \tLoss:  0.09332829713821411\n",
      "\tEpoch 280000 \tLoss:  0.10807383805513382\n",
      "\tEpoch 290000 \tLoss:  0.1026308536529541\n",
      "\tEpoch 300000 \tLoss:  0.08724861592054367\n",
      "Checkpoint saved at iteration 300000\n"
     ]
    }
   ],
   "source": [
    "model = VAE_smiles().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "epochs = 310000\n",
    "batch_size = 64\n",
    "lossi = []\n",
    "for epoch in range(epochs):\n",
    "    # Sample batch\n",
    "    idx = torch.randint(0, Xtr.shape[0], (batch_size,))\n",
    "    Xb = Xtr[idx].to(device)\n",
    "    \n",
    "    # Train the model\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    x_hat, mean, log_var = model(Xb)\n",
    "    loss = loss_function(Xb.view(-1), x_hat.view(-1, vocab_size), mean, log_var)\n",
    "    lossi.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch % 10000 == 0:\n",
    "        print(\"\\tEpoch\", epoch, \"\\tLoss: \", loss.item())\n",
    "    \n",
    "    modelName = 'VAE_smiles'\n",
    "    if epoch % 50000 == 0 and epoch > 0:\n",
    "        checkpoint = {\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': loss.item(),\n",
    "            'iteration': epoch\n",
    "        }\n",
    "        torch.save(checkpoint, f'models/{modelName}_checkpoint_{epoch}.pt')\n",
    "        print(f'Checkpoint saved at iteration {epoch}')\n",
    "    if epoch > 150000:\n",
    "        lr = 1e-4\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = lr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4861,  1.5379,  0.5911, -0.6273, -0.3451,  0.9384, -0.6507,  0.9511,\n",
      "         1.0580,  2.8108])\n",
      "CCCCCCCCCCCCCCCCCCCC CCCCCCCCCCCCCCCCCCCC\n"
     ]
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "model = VAE_smiles().to(device)\n",
    "checkpoint = torch.load('models/VAE_smiles_checkpoint_300000.pt')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "latent_dim = LAT_DIM\n",
    "def generate_smiles(z):\n",
    "    z_sample = torch.tensor([z], dtype=torch.float).to(device)\n",
    "    logits = model.decode(z_sample)\n",
    "    logits = logits.view(-1, vocab_size)\n",
    "    prob = nn.functional.softmax(logits, dim=1)\n",
    "    indices = torch.argmax(prob, dim=-1)\n",
    "    #indices = torch.multinomial(prob, num_samples=1).squeeze(-1)\n",
    "    #print(indices)\n",
    "    return ''.join(itos[ix.item()] for ix in indices).replace('.','')\n",
    "    #return indices\n",
    "samp = torch.randn(latent_dim)\n",
    "#samp = torch.tensor([0,0])\n",
    "print(samp)\n",
    "gen_smiles = generate_smiles(samp.tolist())\n",
    "print(gen_smiles, Chem.MolToSmiles(Chem.MolFromSmiles(gen_smiles)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid SMILES: 1728/10000\n",
      "Unique SMILES: 248/1728\n"
     ]
    }
   ],
   "source": [
    "# Suppress RDKit warnings\n",
    "from rdkit import RDLogger\n",
    "lg = RDLogger.logger()\n",
    "lg.setLevel(RDLogger.CRITICAL)\n",
    "\n",
    "uniqueList = []\n",
    "validCount = 0\n",
    "for i in range(10000):\n",
    "    samp = torch.rand(LAT_DIM)\n",
    "    smi = generate_smiles(samp.tolist())\n",
    "    if Chem.MolFromSmiles(smi):\n",
    "        validCount+=1\n",
    "        canon_smi = Chem.MolToSmiles(Chem.MolFromSmiles(smi))\n",
    "        if canon_smi not in uniqueList:\n",
    "            uniqueList.append(canon_smi)\n",
    "\n",
    "print(f'Valid SMILES: {validCount}/10000')\n",
    "print(f'Unique SMILES: {len(uniqueList)}/{validCount}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CCCCCCCCC', 'CC#CCCC', 'CCCC', 'C#CCCCCCCCCCCCCC', 'CCCCC', 'CCCCCCCCCCCCCCCCCCCC', 'C#CC', 'CC#CC', 'CCCCNNNNNNNNNNNNNNNN', 'C#CCC', 'CCNCC', 'CC', 'C1CCC1', 'C1CC1', 'C=CCC', 'CC=CCCCCCC', 'CCOCC', 'CCC', 'CCCCCCCC', 'CCCCCC', 'CC#CCC', 'CCNC', 'CCC1CCCC1', 'CCCCCCC', 'CCCC1CC1', 'CN', 'C1CO1', 'CCCCCNN', 'CCCCCCCNCC', 'C=CC#CC', 'CC#CCCCCCC', 'CCCOC', 'C=CCNON', 'C#CCCC', 'CC=CCC', 'CCCCCCNC', 'C#CCCCCC', 'CCCCCCNNNNNNNNNNNNNC', 'CCCCCNNC', 'CC#CCCCCCCC', 'CCCCCCNNC', 'CCCCNC', 'C=CCNNCC', 'CCCCCNC', 'C#CCCCC', 'CCC1CCC1', 'C1COONO1', 'CC1CC1', 'C=CCCCCCCCCCCCCCCCCC', 'CCCCCCCCNC', 'CCC1CCCCNC1', 'CC#N', 'C1=CCCCC1', 'CC#CCCCCC', 'CC#CCCCC', 'CCNNCC1OO1', 'CCCNN', 'CCCC1CCC1', 'C', 'CCCNCCNCC', 'CC#CCCCCCCCCCCCC', 'C#CCCCCCC', 'C#CCCCCCCCCCCCCCCCCC', 'CCCCCCCNN', 'C#C', 'CCC1C=CC1', 'CCCC#CN', 'CCCCCCCCCCCCCCCCCCC', 'CCOO', 'OOOOOOOOOOOOOOOOOOOO', 'C1CC12CC2', 'CCCCNN', 'CCOC', 'CCCCCC1CC1', 'CCCCCCCCOC', 'CCCCCNNNNNNCCCCNNNNC', 'CC1CCN1', 'C#N', 'C#CCCC=C', 'C=CCCCCC', 'CON', 'CCNNC', 'CCCCC#N', 'CCCCNCC', 'CCCCCCCCCCCCCCNNCCCC', 'CCCCCCCCCNCC', 'C#CCON', 'CCCCCCCCCCCCC1CCCCC1', 'OCC1CC1', 'C1CNN1', 'CCCCCCCCCCC', 'C=CCCC=CC', 'C1=CCCCCCCCCCCCCCC1', 'CCCCNNC', '', 'CCCCC1CCCC1CCCCCCCCN', 'CCCCCCCON', 'CC1C#C1', 'C#CCNNC', 'CCC1C=C1', 'CNC', 'CCCCNCN', 'C=CC=CC', 'C=CC', 'CCC#CCC', 'CCCCCCCCC1CO1', 'CCCCCCCCCNNC', 'CCC1CC1C', 'CCCC#N', 'CCCCCNOO', 'CCC1CC1', 'CCCCCCCCCCC=N', 'C=CCCC#CC', 'CCCNC', 'CCCCCCCCOCC', 'CCCOCC', 'CCNO', 'C1CCOC1', 'CCCCCCCCCCC1CCCCCCC1', 'C1=CCCNONCC1', 'CCC#N', 'CC=CC', 'CCC1NON1', 'C#CCCC#CCON', 'CCCCCCC#N', 'CCCNNC', 'C=CC=C', 'CCCCCCCNC', 'CCCCCCCCCCC1CC1', 'C=CCCC', 'C=C1CO1', 'CC1NN1N', 'CCCCCCCCCCCCCCC1CC1C', 'CCCCCCN', 'CC1CC1N', 'CCCCOO', 'CC=CCCC', 'CCCOO', 'OC1CCC1', 'CCCCCCCCCCCCCCCCCCNC', 'CC=CCCCCC', 'CCCCC1CN1', 'CCCCCCCCCCCCNC', 'CCCCCCCCCCCCCCCCCCCN', 'C=CCC#CC', 'C#CC=CC', 'CCCCCNCC', 'CCCOCCC', 'CCC#CCNC', 'CC=CCCCCCCCCCCCCCCCC', 'CCCC1CCO1', 'CO', 'C1CCNOCC1', 'C1COC1', 'C#CCCCCCCC', 'CC1CCCCCNNNNNNNNNCC1', 'C=CCCCCCC', 'C=CCCCOC', 'C=CCC=CC', 'CC=C=CCCCCCCCCCCCCCC', 'C1CCNC1', 'CCC1ONNN1OOOCn1[nH]o1', 'CCCCCCCCCCCCCCC', 'CCCCCO', 'CCC1C=CCC1', 'CC1CCCCCCCCCCCCCCCC1', 'C1CCCCCC1', 'C1CCOCC1', 'CCC1CCN1', 'CNO', 'C#CCCNNC', 'C#CCCCCCCCC', 'CCCCCCNOC', 'CCC=C=CCCCCCCCCCCCCC', 'C#CCCCCCCCCCCC', 'CCCCCCCCCCCCCNNNNNCO', 'CCOCCCO', 'CCN=NCCNOC', 'CCCCCC#CN', 'CCCCC1CC1', 'C#CCCCCCCCCC=C', 'CCCCCCCCCCCC', 'CCCCOCC', 'CCCCCN', 'C=CCCCCCCCCCCCCCC', 'CCC=NCNNNN', 'CCCCCCCCCCCCCC1CC1C', 'CCCCCCCO', 'CC=CCCCC', 'CCNOC', 'CCCCCOC', 'C1CCCCCCCCCCCCCCCCC1', 'CCCC1CCCCC1C', 'CCCCCCNN', 'C#CC=C', 'CCCCCCNON', 'OC1CCN1', 'C#CCC=C', 'CCC1CC1CC', 'CCCN', 'CCCCCCCOC', 'CCCCCCCCCCCCCC1CCCC1', 'C#CCNC', 'NNOOO', 'C#CCCCCCCCCCCCCCC', 'CCCNCC1CNN1', 'C=C', 'C1=CCOC1', 'CCCCCCC#CN', 'C1=CCC1', 'CCCCCCCCCCCCC1CC1C', 'C=CCCNN', 'CCCCCCCC1CN1', 'CCCCCCCCCCCCCCCCCCCO', 'C=CCC#CN', 'C#COC', 'C1=CCNONC1', 'OOO', 'CCCCCCCCCCCCCC#CN', 'CCCCCCCNNN', 'CCCCCCCCCC1CC1', 'CCCCC1CO1', 'C#CCCCCCCCCC', 'CCCCCCCCCC', 'C=NOCC', 'CCCCCC1CCCCCCCCCCC1', 'CCCNNO', 'COC', 'CCCCCCOCC', 'CCN', 'CCCCOC', 'CCCCCCCCCCCCCCCC1CC1', 'O', 'CCCC1CO1', 'C#CCOO', 'C1COCO1', 'OO', 'CCCCCC1CO1', 'CCC=C=CNCCCCCCCCCCCC', 'C#CCCCCCCCCCCCC', 'CCCCCCCCCCCCCCCC', 'CCCCCCCC1CCC1', 'CCC1CCO1', 'CCCNCCC', 'CCCCCCCCCCCCCCCCCC', 'CCCCCC#N', 'C=CCCC=C', 'C1=COCCO1']\n"
     ]
    }
   ],
   "source": [
    "print(uniqueList)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
